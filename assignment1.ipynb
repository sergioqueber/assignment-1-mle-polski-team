{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Getting Started: Airbnb Copenhagen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This assignment deals with the most recent Airbnb listings in Copenhagen. The data is collected from [Inside Airbnb](http://insideairbnb.com/copenhagen). Feel free to explore the website further in order to better understand the data. The data (*listings.csv*) has been collected as raw data and needs to be preprocessed.\n",
    "\n",
    "**Hand-in:** Hand in as a group in Itslearning in a **single**, well-organized and easy-to-read Jupyter Notebook. Please just use this notebook to complete the assignment.\n",
    "\n",
    "If your group consists of students from different classes, upload in **both** classes.\n",
    "\n",
    "The first cell does some preprocessing. Please just run these cells and do not change anything. The assignment starts below. Make sure that listings.csv' is in the same folder as this notebook\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install pandas\n",
    "# pip install scikit-learn\n",
    "import pandas as pd\n",
    "import sklearn as sk\n",
    "\n",
    "# load the data\n",
    "data = pd.read_csv('listings.csv')\n",
    "\n",
    "# filter relevant columns\n",
    "data_limited = data[[\"id\",\n",
    "    \"name\",\n",
    "    \"host_id\"  ,\n",
    "    \"host_name\" , \n",
    "    \"neighbourhood_cleansed\"  ,\n",
    "    \"latitude\"  ,\n",
    "    \"longitude\"  ,\n",
    "    \"room_type\"  ,\n",
    "    \"price\"  ,\n",
    "    \"minimum_nights\"  ,\n",
    "    \"number_of_reviews\",  \n",
    "    \"last_review\"  ,\n",
    "    \"review_scores_rating\"  ,\n",
    "    \"review_scores_accuracy\" , \n",
    "    \"review_scores_cleanliness\"  ,\n",
    "    \"review_scores_checkin\"  ,\n",
    "    \"review_scores_communication\"  ,\n",
    "    \"review_scores_location\"  ,\n",
    "    \"review_scores_value\"  ,\n",
    "    \"reviews_per_month\"  ,\n",
    "    \"calculated_host_listings_count\"  ,\n",
    "    \"availability_365\",]]\n",
    "\n",
    "# removing rows with no reviews\n",
    "\n",
    "data_filtered = data_limited.loc[data_limited['number_of_reviews'] != 0]\n",
    "\n",
    "# remove nan\n",
    "\n",
    "data_filtered = data_filtered.dropna()\n",
    "data_filtered.head()\n",
    "\n",
    "# get a list of distinct values from neighbourhood_cleansed columns in data_filtered\n",
    "\n",
    "neighbourhoods = data_filtered[\"neighbourhood_cleansed\"].unique()\n",
    "\n",
    "# replace e.g. Nrrbro with Nørrebro in neighbourhood_cleansed column\n",
    "\n",
    "data_filtered[\"neighbourhood_cleansed\"] = data_filtered[\"neighbourhood_cleansed\"].replace(\"Nrrebro\", \"Nørrebro\")\n",
    "data_filtered[\"neighbourhood_cleansed\"] = data_filtered[\"neighbourhood_cleansed\"].replace(\"sterbro\", \"Østerbro\")\n",
    "data_filtered[\"neighbourhood_cleansed\"] = data_filtered[\"neighbourhood_cleansed\"].replace(\"Vanlse\", \"Vanløse\")\n",
    "data_filtered[\"neighbourhood_cleansed\"] = data_filtered[\"neighbourhood_cleansed\"].replace(\"Brnshj-Husum\", \"Brønshøj-Husum\")\n",
    "neighbourhoods = data_filtered[\"neighbourhood_cleansed\"].unique()\n",
    "\n",
    "# Remove dollar signs and commas and convert to float - note the prices are actually in DKK\n",
    "data_filtered['price'] = data_filtered['price'].replace('[\\$,]', '', regex=True).astype(float)\n",
    "\n",
    "# Calculate the median price\n",
    "median_price = data_filtered['price'].median()\n",
    "\n",
    "# Create a new column 'price_category' with 0 for 'affordable' and 1 for 'expensive'\n",
    "data_filtered['price_category'] = (data_filtered['price'] > median_price).astype(int)\n",
    "\n",
    "display(data_filtered.head())\n",
    "\n",
    "# Describe the apartments using a wordcloud\n",
    "# Remember to install packages\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Combine the two lists of stop words\n",
    "stop_words = ['Østerbro', 'Copenhagen', 'København', 'in', 'bedroom', 'bedrooms', 'bed', 'beds', 'bath', 'baths', 'Frederiksberg', 'V', 'Ø', 'SV', 'S', 'N', 'K', 'C', 'W', 'kbh', 'Ballerup', 'Hellerup', 'Valby', 'Vanløse', 'Brønhøj', 'Nørrebro', 'Vesterbro', \"CPH\", \"with\", \"to\", \"of\", \"a\", \"the\", \"på\", \"i\", \"med\", \"af\", \"at\", \"city\", \"by\", \"apartment\", \"appartment\", \"lejlighed\", \"flat\", \"m2\", \"apt\"]\n",
    "\n",
    "# Convert the 'name' column to a single string\n",
    "text = ' '.join(data_filtered['name'].astype(str))\n",
    "\n",
    "# Create and generate a word cloud image\n",
    "wordcloud = WordCloud(stopwords=stop_words, background_color=\"white\", width=800, height=400).generate(text)\n",
    "\n",
    "# Display the generated word cloud\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Your tasks start here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 1. Since data science is so much fun, provide a word cloud of the names of the hosts, removing any names of non-persons. Does this more or less correspond with the distribution of names according to [Danmarks Statistik](https://www.dst.dk/da/Statistik/emner/borgere/navne/navne-i-hele-befolkningen)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# State your solution here. Add more cells if needed.\n",
    "\n",
    "host_names = data_filtered['host_name'].dropna().astype(str)\n",
    "business_words = ['airbnb', 'rental', 'apartment', 'home', 'house', 'property', 'stay', 'hosting', \n",
    "                  'management', 'company', 'group', 'team', 'service', 'copenhagen', 'cph']\n",
    "\n",
    "def is_person_name(name):\n",
    "    name_lower = name.lower()\n",
    "    # Remove if contains numbers\n",
    "    if any(char.isdigit() for char in name):\n",
    "        return False\n",
    "    # Remove if contains business-related words\n",
    "    if any(word in name_lower for word in business_words):\n",
    "        return False\n",
    "    # Remove if too long (likely business names)\n",
    "    if len(name) > 30:\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "# Filter for person names only\n",
    "person_names = [name for name in host_names if is_person_name(name)]\n",
    "\n",
    "text = ' '.join(person_names)\n",
    "\n",
    "name_stopwords = ['and', 'og', '&', 'the', 'de', 'van', 'von', 'el', 'la']\n",
    "\n",
    "namesworldcloud = WordCloud(stopwords=name_stopwords, background_color=\"white\", \n",
    "                           width=800, height=400, max_words=100).generate(text)\n",
    "\n",
    "# Display the generated word cloud\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.imshow(namesworldcloud, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Using non-scaled versions of latitude and longitude, plot the listings data on a map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# State your solution here. Add more cells if needed.\n",
    "import contextily as ctx\n",
    "price_cap = data_filtered['price'].quantile(0.95)\n",
    "data_plot = data_filtered[data_filtered['price'] < price_cap]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15, 12))\n",
    "scatter = ax.scatter(data_plot['longitude'], data_plot['latitude'], \n",
    "            c=data_plot['price'], cmap='coolwarm', alpha=0.6, s=10, )\n",
    "\n",
    "ax.set_xlim(data_plot['longitude'].min() - 0.01, data_plot['longitude'].max() + 0.01)\n",
    "ax.set_ylim(data_plot['latitude'].min() - 0.01, data_plot['latitude'].max() + 0.01)\n",
    "\n",
    "\n",
    "ctx.add_basemap(ax, crs='EPSG:4326', source=ctx.providers.CartoDB.Positron)\n",
    "\n",
    "cbar = plt.colorbar(scatter, ax=ax, shrink=0.6)\n",
    "cbar.set_label('Price (DKK)', rotation=270, labelpad=15)\n",
    "\n",
    "ax.set_xlabel('Longitude')\n",
    "ax.set_ylabel('Latitude')\n",
    "ax.set_title('Copenhagen Airbnb Listings Colored by Price')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Create boxplots where you have the neighbourhood on the x-axis and price on the y-axis. What does this tell you about the listings in Copenhagen? Keep the x-axis as is and move different variables into the y-axis to see how things are distributed between the neighborhoods to create different plots (your choice)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of distinct neighbourhoods\n",
    "neighbourhoods = data_filtered['neighbourhood_cleansed'].unique()\n",
    "neighbourhoods_list = [x for x in neighbourhoods]\n",
    "\n",
    "# Create a function to make lists of values for each neighbourhood\n",
    "# The lists will be named after the neighbourhoods and contain just numeric values\n",
    "def create_neighbourhood_lists(column):\n",
    "    list = []\n",
    "    for neighborhood in neighbourhoods:\n",
    "        data_points = data_filtered.loc[data_filtered['neighbourhood_cleansed'] == neighborhood, column].tolist()\n",
    "        var_name = neighborhood.replace(\" \", \"_\").replace(\"-\", \"_\").replace(\"ø\", \"oe\").replace(\"Ø\", \"Oe\").replace(\"æ\", \"ae\").replace(\"å\", \"aa\").replace(\"Å\", \"Aa\")\n",
    "        globals()[var_name] = data_points\n",
    "        list.append(data_points)\n",
    "    return list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the function, create box plot for prices\n",
    "neighbourhoods_prices = create_neighbourhood_lists('price')\n",
    "plt.boxplot(neighbourhoods_prices, showfliers=False)\n",
    "plt.title('Price Distribution by Neighbourhood')\n",
    "plt.xlabel('Neighbourhood')\n",
    "plt.xticks(ticks=range(1, 12), labels=neighbourhoods_list, rotation=45, ha='right')\n",
    "plt.ylabel('Price')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neighbourhoods_min_nights = create_neighbourhood_lists('minimum_nights')\n",
    "plt.boxplot(neighbourhoods_min_nights, showfliers=False)\n",
    "plt.title('Minimum Nights Distribution by Neighbourhood')\n",
    "plt.xlabel('Neighbourhood')\n",
    "plt.xticks(ticks=range(1, 12), labels=neighbourhoods_list, rotation=45, ha='right')\n",
    "plt.ylabel('Minimum Nights')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an overall review column, with a value of mean reviews\n",
    "\n",
    "review_columns = [\n",
    "    \"review_scores_rating\",\n",
    "    \"review_scores_accuracy\",\n",
    "    \"review_scores_cleanliness\",\n",
    "    \"review_scores_checkin\",\n",
    "    \"review_scores_communication\",\n",
    "    \"review_scores_location\",\n",
    "    \"review_scores_value\"\n",
    "]\n",
    "\n",
    "data_filtered[\"review_overall\"] = data_filtered[review_columns].mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neighbourhoods_reviews = create_neighbourhood_lists('review_overall')\n",
    "\n",
    "plt.boxplot(neighbourhoods_reviews, showfliers=False)\n",
    "plt.title('Reviews Scores Distribution by Neighbourhood')\n",
    "plt.xlabel('Neighbourhood')\n",
    "plt.xticks(ticks=range(1, 12), labels=neighbourhoods_list, rotation=45, ha='right')\n",
    "plt.ylabel('Reviews')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Do a descriptive analysis of the neighborhoods. Include information about room type in the analysis as well as one other self-chosen feature. The descriptive analysis should contain mean/average, mode, median, standard deviation/variance, minimum, maximum and quartiles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n--- Counts of Room Types by Neighbourhood ---\")\n",
    "room_type_counts = pd.crosstab(data_filtered['neighbourhood_cleansed'], data_filtered['room_type'])\n",
    "display(room_type_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_score_stats = data_filtered.groupby('neighbourhood_cleansed')['review_overall'].describe()\n",
    "display(review_score_stats)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n--- Custom Descriptive Statistics for Price by Neighbourhood ---\")\n",
    "custom_price_stats = data_filtered.groupby('neighbourhood_cleansed')['price'].agg(\n",
    "    min_price='min',\n",
    "    mean_price='mean',\n",
    "    median_price='median',\n",
    "    max_price='max',\n",
    "    std_deviation='std',\n",
    "    variance='var',\n",
    "    count='count'\n",
    ")\n",
    "\n",
    "display(custom_price_stats.round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Based on self-chosen features, and with \"price_category\" as your target, develop a k-Nearest Neighbor model to determine whether a rental property should be classified as 0 or 1. Remember to divide your data into training data and test data. Comment on your findings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_data = data_filtered[[\n",
    "    \"latitude\"  ,\n",
    "    \"longitude\"  ,\n",
    "    \"minimum_nights\"  ,\n",
    "    \"review_overall\",\n",
    "    \"calculated_host_listings_count\"  ,\n",
    "    \"availability_365\",\n",
    "    \"price_category\"]]\n",
    "\n",
    "one_hot_neighbourhood = pd.get_dummies(data_filtered['neighbourhood_cleansed'], dtype=float)\n",
    "one_hot_room_type = pd.get_dummies(data_filtered['room_type'], dtype=float)\n",
    "\n",
    "ml_data = pd.concat([ml_data, one_hot_room_type, one_hot_neighbourhood], axis=1)\n",
    "\n",
    "ml_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "y = ml_data['price_category']\n",
    "X = ml_data.drop(columns=['price_category'])\n",
    "\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KNeighborsClassifier(n_neighbors=7)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print(\"Score on training data:\", model.score(X_train, y_train))\n",
    "print(\"Score on test data:\", model.score(X_test, y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
